# -*- coding: utf-8 -*-
"""Germán_Martin_NIDO9W_ML_ZH_20241211_14.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/183I__N3-Wvcc0D3SlhnxvZbcYkWFueBi

# Zárthelyi dolgozat

* Másold le a dokumentumot a megszokott módon és nevezd át, úgy, hogy az
tartalmazza a nevedet és a Neptun-kódodat (Vezetknév_Keresztnév-NEPTUNKÓD)!
Miután átnevezted, oszd meg a dokumentumot velem (`rifarkas@gmail.com`) szerkesztési joggal!

* A zárthelyi megírásához használhattok bármilyen segédanyagot, kivéve egymást. Se online, se offline!
* Csak az órai notebookokban használt módszereket (library, osztály, függvény, stb) fogadom el a megoldásban!
* Kérlek benneteket, hogy ahol csak lehetséges, legjobb tudomásotok szerint kommentezzétek fel a kódot, illetve a feladatokra válaszoljatok szövegesen is (1 mondat).

# 1/A feladat

Készítsd elő az alábbi adatbázist, hogy gépi tanulási kísérletek végrehajtására alkalmas legyen!
A célváltozó az utolsó oszlop, a `stroke`.

 https://raw.githubusercontent.com/levotvos/datascience_2024/refs/heads/main/healthcare-dataset-stroke-data.csv
"""

import pandas as pd

df = pd.read_csv('https://raw.githubusercontent.com/levotvos/datascience_2024/refs/heads/main/healthcare-dataset-stroke-data.csv')
df = df.dropna()

df = pd.get_dummies(df, columns=['gender', 'ever_married', 'work_type', 'Residence_type', 'smoking_status'], drop_first=True)
X = df.drop(columns=['stroke'])
y = df['stroke']

print(df.head())

"""# 1/B feladat

Azt szeretnénk minél jobban megjósolni, hogy sztrókot kaphat-e egy adott személy, bizonyos egészségügyi adatai alapján. Hajts végre gépi tanulási kísérletet legalább két különböző fajta modellel!

*Az elsődleges szempont legyen számunkra, hogy inkább előnyben részesítsük azt, hogy ha sztrókot jóslunk, de mégsem áll fenn, minthogy egészségesnek mondjunk egy pácienst, úgy hogy sztrókot kaphat. Igyekezzünk azonban a minél jobb precizitás elérésére is, az egészségügyi költségek miatt.*
"""

import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import confusion_matrix, classification_report, f1_score
from imblearn.under_sampling import NearMiss

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)

nm = NearMiss()
X_train_resampled, y_train_resampled = nm.fit_resample(X_train, y_train)

logreg = LogisticRegression(max_iter=5000, class_weight='balanced', solver='liblinear', random_state=42)
logreg.fit(X_train_resampled, y_train_resampled)
y_pred_logreg = logreg.predict(X_test)

print("Logistic Regresszió (liblinear solver):")
print(confusion_matrix(y_test, y_pred_logreg))
print(classification_report(y_test, y_pred_logreg))

dtree = DecisionTreeClassifier(max_depth=7, class_weight='balanced', random_state=42)
dtree.fit(X_train_resampled, y_train_resampled)
y_pred_dtree = dtree.predict(X_test)

print("\nDöntési Fa:")
print(confusion_matrix(y_test, y_pred_dtree))
print(classification_report(y_test, y_pred_dtree))

f1_logreg = f1_score(y_test, y_pred_logreg)
f1_dtree = f1_score(y_test, y_pred_dtree)

print(f"\nF1-score (Logistic Regresszió): {f1_logreg:.2f}")
print(f"F1-score (Döntési Fa): {f1_dtree:.2f}")

"""# 1/C fealdat

Melyik lett a legerősebb/leghasznosabb jellemző az 1/B feladatban használt modellek valamelyikének? (elég ha egy modellre megcsinálod)
"""

import numpy as np
import matplotlib.pyplot as plt

feature_importance = np.abs(logreg.coef_[0])

sorted_idx = np.argsort(feature_importance)[::-1]

feature_names = X.columns
top_features = feature_names[sorted_idx]

print("Legerősebb jellemzők a Logistic Regresszióban:")
for i in range(10):
    print(f"{top_features[i]}: {feature_importance[sorted_idx[i]]:.4f}")

plt.barh(top_features[:10], feature_importance[sorted_idx][:10])
plt.xlabel('Jellemző fontosság')
plt.title('Legerősebb jellemzők a Logistic Regresszióban')
plt.show()

"""# 2 feladat

Hajts végre paraméter hangolást az 1/B feladatban használt modellek valamelyikén! El tudtál érni jobb eredményeket így, mint az 1/B-ben? (elég ha egy modellre megcsinálod)
"""

from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import make_scorer

parameters = {
    'C': [0.001, 0.01, 0.1, 1, 10, 100],
    'max_iter': [1000, 5000],
    'solver': ['liblinear'],
}

logreg = LogisticRegression(class_weight='balanced', random_state=42)

clf = GridSearchCV(logreg, parameters, cv=3, scoring=make_scorer(f1_score, pos_label=1), verbose=3)
clf.fit(X_train_resampled, y_train_resampled)

best_params = clf.best_params_
best_score = clf.best_score_
print("Legjobb paraméterek:", best_params)
print("Legjobb pontszám (cross-validation):", best_score)

y_pred_best = clf.predict(X_test)
print("\nLogisztikus Regresszió (hangolt paraméterek):")
print(confusion_matrix(y_test, y_pred_best))
print(classification_report(y_test, y_pred_best))

f1_best = f1_score(y_test, y_pred_best)
print(f"\nF1-score (Legjobb modell): {f1_best:.2f}")

"""# 3/A feladat

Listázd ki a negyedik (3-as indexű) szöveges értékeléshez (`Review Text`) 4 darab leghasonlóbb értékelést az adatbázisból!

**Megjegyzés:** előfordulhat, hogy túlságosan nagy a jellemző mátrix mérete, így a tanításnál kifuthatsz a memóriából és/vagy nagyon sokáig fut a tanulás. Ha ilyenbe futnál bele, nézd át a jellemzőkinyerő osztály konstruktorának argumentumait, hogy kisebb jellemző mátrixot kapj.

https://raw.githubusercontent.com/levotvos/datascience_2024/refs/heads/main/clothing_reviews.csv
"""

from gensim.models import Word2Vec
import re

url = "https://raw.githubusercontent.com/levotvos/datascience_2024/refs/heads/main/clothing_reviews.csv"
df = pd.read_csv(url)

df = df.dropna(subset=["Review Text"])

def preprocess_text(text):
    text = text.lower()
    text = re.sub(r'[^a-z\s]', '', text)
    return text

df['cleaned_text'] = df['Review Text'].apply(preprocess_text)

tokenized_texts = df['cleaned_text'].apply(str.split)

word2vec_model = Word2Vec(sentences=tokenized_texts, vector_size=100, window=5, min_count=1, workers=4)

def compute_doc_vector(tokens, model):
    vectors = [model.wv[word] for word in tokens if word in model.wv]
    if len(vectors) == 0:
        return np.zeros(model.vector_size)
    return np.mean(vectors, axis=0)

df['doc_vector'] = tokenized_texts.apply(lambda x: compute_doc_vector(x, word2vec_model))

def cosine_similarity_manual(v1, v2):
    dot_product = np.dot(v1, v2)
    norm_v1 = np.linalg.norm(v1)
    norm_v2 = np.linalg.norm(v2)
    if norm_v1 == 0 or norm_v2 == 0:
        return 0
    return dot_product / (norm_v1 * norm_v2)

query_index = 3
query_vector = df.iloc[query_index]['doc_vector']

df['similarity'] = df['doc_vector'].apply(lambda x: cosine_similarity_manual(query_vector, x))

similar_indices = df.sort_values(by='similarity', ascending=False).index[1:5]
similar_texts = df.iloc[similar_indices]["Review Text"]

print(f"Az {query_index}. értékeléshez leginkább hasonló szövegek:")
for i, text in enumerate(similar_texts, start=1):
    print(f"{i}. {text}")

"""# 3/B feladat

Old meg a 3/A feladát úgy, hogy dokumentum beágyazási vektorokat használsz!
Egy dokumentum beágyazási vektora a szavai beágyazás vektorának az átlaga.

Használd az alábbi kódrészleteket!
"""

for word in text.split():
    if word in static_word2vec.wv:  # Ellenőrzi, hogy a szóhoz tartozik-e vektor
        vectors.append(static_word2vec.wv[word])

if len(vectors) == 0:  # Ha nincs érvényes szó a szövegben
    return np.zeros(100)  # 100 dimenziós nullvektor
else:
    return np.mean(vectors, axis=0)  # Átlag a szavak vektorai alapján



"""# 4 feladat
Mi lenne a 3/A feladatra a predikció a negyedik reviewnak (3-as indexű sor) ha azt a huggingface `unsloth/Llama-3.2-1B` nagy nyelvi modell generálja (ami egy GPT típusú modell)!
"""

from transformers import AutoTokenizer, AutoModelForCausalLM

tokenizer = AutoTokenizer.from_pretrained("unsloth/Llama-3.2-1B")
model = AutoModelForCausalLM.from_pretrained("unsloth/Llama-3.2-1B")

query_review = df.iloc[3]["Review Text"]

inputs = tokenizer(query_review, return_tensors="pt", max_length=512, truncation=True)

inputs["attention_mask"] = inputs["attention_mask"] if "attention_mask" in inputs else None
inputs["pad_token_id"] = tokenizer.eos_token_id

outputs = model.generate(inputs["input_ids"], max_length=150, num_return_sequences=1, no_repeat_ngram_size=2, temperature=0.7, do_sample=True)

generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)

print("Eredeti szöveg:")
print(query_review)
print("\nGenerált szöveg:")
print(generated_text)