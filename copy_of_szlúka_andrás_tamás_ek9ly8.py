# -*- coding: utf-8 -*-
"""Copy of Szlúka-András-Tamás-EK9LY8

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cNZMScxp1y6jmE91t7PrULJ7ghvv1k3o

# 1. feladat

Az https://archive.ics.uci.edu/ml/machine-learning-databases/00272/SkillCraft1_Dataset.csv adatbázis StarCraft2 játékosok statisztikáit tartalmazza. Kérdés, hogy ezekből az adatokból mennyire jelezhető előre, hogy melyik ligában játszik a játékos.

Hajts végre regressziós gépi tanulási kísérletet a `LeagueIndex` célváltozón (1-8 intervallum), úgy hogy a `GameID > 7000` játékosokat használod kiértékelő adatbázisnak.

Vigyázz! Az adatbázisban `?` jelöli a hiányzó értékeket.
"""

import pandas as pd
# töltsük be az adatbázist
df = pd.read_csv("https://archive.ics.uci.edu/ml/machine-learning-databases/00272/SkillCraft1_Dataset.csv",na_values="?")
df.head() # nézzünk rá!

df.describe()
df[df.GameID > 7000].shape #kiértékelő adathalmaz mérete

df=df.dropna() #mivel vannak NAN értékek az adatbázisban, most kidobjuk őket, hogy ne okozzanak gondot később
df.shape #az egész adatbázis mérete

"""Jól látható, hogy a tanító adatbázis jóval nagyobb, mint a kiértékelő és ez rendben is van így. A tanítóé 3338-886=2452 sorból áll, a kiértékelőé meg 886-ból."""

features = df.loc[:,"Age":]
df.loc[:,"Age":] # jellemzők az Age változó szerint

# szétválasztjuk a tanító- és teszthalmazokat, különvéve a jellemzőket és az osztálycímkét
trainFeatures = df[df.GameID <= 7000].loc[:,"Age":] # A 7000-nél kisebb egyenlőek Age szerint, tanító adatbázis része
trainLabels = df[df.GameID <= 7000].LeagueIndex # A 7000-nél kisebb egyenlőek osztálycímke(LeagueIndex) szerint, tanító adatbázis része
testFeatures = df[df.GameID > 7000].loc[:,"Age":] # A 7000-nél nagyobbak Age szerint a kiértékelő adatbázison
testLabels =  df[df.GameID > 7000].LeagueIndex # A 7000-nél nagyobbak a célváltozó szerint a kiértékelő adatbázison

from sklearn.tree import DecisionTreeRegressor

dt = DecisionTreeRegressor(min_samples_leaf=50) #DecisionTreeRegressor (azaz döntési fa regresszióra) használata
dt.fit(trainFeatures, trainLabels) # tanítás a tanító adatbázison
prediction = dt.predict(testFeatures) # predikció a kiértékelő adatbázison

from sklearn.metrics import mean_squared_error # MSE (RMSE végső gyökvonás nélkül)
mean_squared_error(prediction, testLabels) #MSE meghatározása

"""És megkaptuk a Mean Squared Errort, 1,0257. Minél alacsonyabb ez az érték, annál jobb."""

from sklearn.dummy import DummyRegressor
dummy = DummyRegressor(strategy='mean') # tanító adatbázis címkéinek átlaga lesz mindig a predikció
dummy.fit(trainFeatures, trainLabels)
mean_squared_error(dummy.predict(testFeatures), testLabels)

"""Ez pedig a baseline eredménye, amit -mivel regressziós feladatról van szó- DummyRegressor-ral kaptam meg. Itt a hiba 2 felett van és mondtam, hogy akkor lesz minél jobb az érték, minél kisebb. A korábban kapott 1,0257 majdnem feleannyi, mint a baseline 2,0099-es errorja, ami nekünk jó hír.:)

# 2. feladat
Melyik jellemző a legfontosabb a regressziós modellben?

Építs erre az egy jellemzőre egy döntési modellt (akár kézzel, akár gépi tanulva)!
"""

dt = DecisionTreeRegressor(max_depth=1)

dt.fit(trainFeatures, trainLabels) # tanítás a tanító adatbázison

root = dt.tree_.feature[0] # gyökércsúcsban lévő feature indexe
trainFeatures.columns[root] # a legfontosabb jellemző kinyerése

"""Az ActionLatency lesz a legfontosabb jellemző."""

prediction = dt.predict(testFeatures) # predikció a kiértékelő adathalmazon
mean_squared_error(prediction, testLabels)

"""A döntési modellre kapott átlagos négyzetes hiba (MSE): 1,4588. Minél kisebb az érték, annál jobb, mivel hibát mérünk.

# 3. feladat

A jellemzők alapján csinálj egy 2D leképezést és ebben a térben jelenítsd meg az egyedeket. Az egyedekhez tartozó jelek színe legyen az életkor (tipp: használhatod a `cmap='Spectral'` argumentumot a plothoz)
"""

### SVD dimenzió csökkentés:
# ha 2D a cél, akkor a két legnagyobb sajátértékhez tartozó sajátvektorokat vegyük csak figyelembe
# ezeket az oszlopokat fel tudjuk használni arra, hogy vizualizáljunk
from sklearn.decomposition import TruncatedSVD

svd = TruncatedSVD(n_components=2) # az első 2 komponenst tartjuk csak meg (2Dbe mappelünk)
m2d = svd.fit_transform(features) # az adatbázison megcsinálja a leképezést
m2d

from sklearn.cluster import KMeans
k=10
kmeans = KMeans(n_clusters=k).fit(m2d)

kmeans.cluster_centers_

import matplotlib.pyplot as plt
plt.figure(figsize=(15,15))       # beállítjuk a kép méretét, a default érték pici
plt.scatter( m2d[:,0],   # minden pont egy film, aminek x koordinátája az SVD leképezés első komponense
             m2d[:,1],   # y koordinátája az SVD leképezés második komponense (2D)
             c=df["Age"], cmap='Spectral') # színe pedig adott, hogy az életkor alapján legyen beállítva

"""Vagy tényleg ennyiből áll a plot, mert leredukáltuk 2D-re, vagy ami a másik (talán valószínűbb) opció: valami érezhetően nincs rendben, csak nem tudok rájönni, mi...:D"""