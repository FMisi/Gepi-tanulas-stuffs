# -*- coding: utf-8 -*-
"""Kiss_Ádám_GK4DQO másolata

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Ix8X361zregd6CKW8cfdW2seKgl2KbZk

<div class="markdown-google-sans">

# Zárthelyi dolgozat
</div>

- Másold le a dokumentumot a megszokott módon és nevezd át, úgy, hogy az tartalmazza a nevedet és a Neptun-kódodat (Vezetknév_Keresztnév-NEPTUNKÓD)!
- Miután átnevezted, oszd meg a dokumentumot velünk szerkesztési joggal! (az email-címeinket a táblán találod)


- Kérünk benneteket, hogy ahol csak lehetséges, legjobb tudomásotok szerint kommentezzétek fel a kódot, illetve válaszoljatok szövegesen is.
- A hangsúly azon van, ahogyan előállítjátok a kért adatokat, nem azok pontosságán, így ha valahol hibás predikációt ad a modell nem gond, (de lehetőség szerint ismerjétek fel, és írjátok oda, hogy mi lenne az elvárt viselkedés szerintetek).
- <u>Ezen felül, ha előre láthatóan ki fogtok futni az időből, akkor lehetőség szerint írjátok le szövegesen, mit csináltatok volna a maradék feladatokkal!</u>


- A zárthelyi megírásához használhattok bármilyen segédanyagot, kivéve egymást. **Se online, se offline!**


**Sok Sikert Kívánunk!**

---

# 1. feladat

Az https://github.com/kiscsonti/student_data/raw/main/mushroom_dataset.zip fájl egy adatbázit tartalmaz gombákról. Töltsd le és írj egy egyszerű döntési szabályt (egy jellemzőből), ami jobban dönti el, hogy ehető-e a gomba (`class=e`) mint a leggyakoribb osztály baseline. Kiértékelési metrikaként a mérgező osztály (`class=p`) F1 Score-ját használd!

## A jellemzőkről leírás:

* class: edible=e, poisonous=p
* cap-surface: fibrous=f,grooves=g,scaly=y,smooth=s
* gill-attachment: attached=a,descending=d,free=f,notched=n
* stalk-shape: enlarging=e,tapering=t
* stalk-root: bulbous=b,club=c,cup=u,equal=e,rhizomorphs=z,rooted=r,missing=?
* veil-type: partial=p,universal=u
* veil-color: brown=n,orange=o,white=w,yellow=y
* ring-number: none=n,one=o,two=t
"""

import pandas as pd
df = pd.read_csv('https://raw.githubusercontent.com/kiscsonti/student_data/main/mushroom.csv')
df.head()

df['eheto'] = df['class'] == 'e'
df['mergezo'] = df['class'] == 'p'

pd.crosstab(df.eheto,df.mergezo)

pd.crosstab(df.eheto, df.mergezo).plot(kind='bar', stacked=False)

print("accuracy:", df['eheto'].value_counts() / len(df) )

~(df.eheto=="no")

pred = ~(df.eheto=='no')

print("accuracy:", (pred == df.mergezo).sum() / len(df))

import numpy as np
from sklearn.metrics import f1_score

f1_score(df.mergezo, pred)

from sklearn.dummy import DummyClassifier
# baseline classifier
#strategies : {“most_frequent”, “prior”, “stratified”, “uniform”, “constant”}
dummy_clf = DummyClassifier(strategy="most_frequent")
dummy_clf.fit(df.eheto,df.mergezo)
dummy_preds = dummy_clf.predict(df.eheto)
dummy_preds
from sklearn.metrics import accuracy_score
accuracy_score(df.mergezo, dummy_preds)
dummy_clf.score(df.eheto,df.mergezo)

"""# 2. feladat

Hajts végre gépi tanulási kísérletet arra nézve, hogy egy gomba mérgező/ehető mennyire jól állapítható meg a jellemzők alapján! Használd az adat véletlenszerű 20%-át kiértékelő adatbázisnak.
"""

from sklearn.model_selection import train_test_split
train_data, test_data = train_test_split(df, train_size=0.20, random_state=42)

##Szószákhoz jellemző és cimkekinyerés
train_eheto = train_data.eheto
train_mergezo = train_data.mergezo

test_eheto = test_data.eheto
test_mergezo = test_data.mergezo

classlabel  = df['eheto'] == True
features = df.iloc[:,:-1]

classlabel.value_counts()[False] / len(classlabel)

from sklearn import tree
dt= tree.DecisionTreeClassifier()

from sklearn import preprocessing
# ha csak a diszkrét változókat one hot encodoljuk:
ohe = preprocessing.OneHotEncoder(handle_unknown='ignore') #one hot encoding
object_features = features.select_dtypes(include=['object'])
object_features.head()

cat_features = ohe.fit_transform(object_features)
cat_features

# Fit and transform the categorical features
cat_features = ohe.fit_transform(object_features)

# Get feature names (for newer versions of scikit-learn)
feature_names = ohe.get_feature_names_out(object_features.columns)

# Convert the sparse matrix to a dense array
cat_features_dense = cat_features.toarray()

# Create DataFrame from encoded features
ohe_features = pd.DataFrame(cat_features_dense, columns=feature_names, index=object_features.index)

# Print the resulting DataFrame
print(ohe_features)

features.select_dtypes(exclude=['object'])

ohe_features = pd.concat( [features.select_dtypes(exclude=['object']), ohe_features], axis=1, join='inner' )
ohe_features

ohe_features = ohe_features.dropna()

dt = tree.DecisionTreeClassifier()
dt.fit(ohe_features, classlabel)

!pip install scikit-learn==1.0.2
!pip install eli5
import eli5

eli5.show_weights(dt, feature_names=list(ohe_features.columns), show=["decision_tree"], filled="True")

dt = tree.DecisionTreeClassifier() # legfeljebb 3 mély fát építhet
dt.fit(ohe_features, classlabel)
eli5.show_weights(dt, feature_names=list(ohe_features.columns), show=["decision_tree"], filled="True")

prediction = dt.predict(ohe_features)
prediction

from sklearn.metrics import accuracy_score
accuracy_score(prediction, classlabel)

from sklearn.dummy import DummyClassifier

dummy_clf = DummyClassifier(strategy="most_frequent") # tanító adatbázis leggyakoribb osztálya lesz mindig a predikció
dummy_clf.fit(features, classlabel) # ugyanazon a tanító adatbázison "tanítjuk"
baseline_prediction = dummy_clf.predict(features) # predikció a kiértékelő adatbázison
accuracy_score(baseline_prediction, classlabel)

"""# 3. feladat
Próbálj ki egy másik gépi tanuló algoritmust is a 2. feladatra. Mindkettőnek hangold be a meta-paraméterit. (bónus feladat: a meta-paraméter értékekre a túltanási ábra kirajzolása)

A végén szövegként írd le, hogy a két algoritmus közül melyik a jobb!

"""

classlabel  = df['eheto'] == True
features = df.iloc[:,:-1]

from sklearn.feature_extraction.text import CountVectorizer
count = CountVectorizer()

from sklearn.model_selection import train_test_split

trainFeatures,testFeatures,trainLabels,testLabels = train_test_split(features, df.eheto, test_size=.30)
trainFeatures.shape # 338 egyed, 20 jellemző (különböző műfajok)

# Regressziós döntési fát érdemes használnunk, hiszen csak 20 bináris jellemzőnk van
from sklearn.neighbors import KNeighborsRegressor

dt = KNeighborsRegressor(n_neighbors=9) # döntési fa regresszióra

trainFeatures = trainFeatures.replace('e', 0)
testFeatures = testFeatures.replace('e', 0)
trainFeatures = trainFeatures.replace('p', 1)
testFeatures = testFeatures.replace('p', 1)
trainFeatures = trainFeatures.replace('f', 1)
testFeatures = testFeatures.replace('f', 1)

dt.fit(trainFeatures, trainLabels) # tanítás a tanító adatbázison
prediction = dt.predict(testFeatures) # predikció a teszt adatbázison

prediction

from sklearn.metrics import mean_squared_error # MSE (RMSE végső gyökvonás nélkül)
mean_squared_error(prediction, testLabels)

from sklearn.dummy import DummyRegressor
dummy = DummyRegressor(strategy='mean') # tanító adatbázis címkéinek átlaga lesz mindig a predikció
dummy.fit(trainFeatures, trainLabels)
mean_squared_error(dummy.predict(testFeatures), testLabels)

